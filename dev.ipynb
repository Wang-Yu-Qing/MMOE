{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 22:57:33.391845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, tf.Tensor): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def buildSample(fea, matrital, income):\n",
    "    data = {\n",
    "        'fea': _bytes_feature(tf.io.serialize_tensor(fea)),\n",
    "        'marital': _int64_feature(matrital),\n",
    "        'income': _int64_feature(income)\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "\n",
    "    return example\n",
    "\n",
    "def parseLine(line):\n",
    "    fields = line.strip().split(\",\")\n",
    "    return int(fields[0]), int(fields[1]), [float(x) for x in fields[2:]]\n",
    "\n",
    "# save as tfrecord to disk, or use `tf.data.Dataset.from_tensor_slices` in memory\n",
    "train_data_path = \"data/census/tfrecords/train.tfrecords\"\n",
    "test_data_path = \"data/census/tfrecords/test.tfrecords\"\n",
    "with tf.io.TFRecordWriter(train_data_path) as writer:\n",
    "    with open(\"data/census/train_data.csv\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            marital, income, fea = parseLine(line)\n",
    "            example = buildSample(fea, marital, income)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "with tf.io.TFRecordWriter(train_data_path) as writer:\n",
    "    with open(\"data/census/test_data.csv\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            marital, income, fea = parseLine(line)\n",
    "            example = buildSample(fea, marital, income)\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMOEDense(object):\n",
    "    def __init__(self, nTasks, nExperts, inputDim, expertDim, hiddenDim):\n",
    "        self.nTasks = nTasks\n",
    "        self.nExperts = nExperts\n",
    "        self.inputDim = inputDim\n",
    "        self.expertDim = expertDim\n",
    "        # experts (nExperts, inputDim, expertDim)\n",
    "        expertInit = tf.initializers.truncated_normal(mean=0.0, stddev=1.0)\n",
    "        self.experts = tf.Variable(expertInit(shape=(nExperts, inputDim, expertDim), dtype=tf.float32), name=\"experts\")\n",
    "        # gates, (nTasks, inputDim, nExpert)\n",
    "        gateInit = tf.initializers.truncated_normal(mean=0.0, stddev=1.0)\n",
    "        self.gates = tf.Variable(gateInit(shape=(nTasks, inputDim, nExperts), dtype=tf.float32), name=\"gates\")\n",
    "        # towers' mlp for each task, (nTasks, expertDim, hiddenDim)\n",
    "        towersInit = tf.initializers.truncated_normal(mean=0.0, stddev=1.0)\n",
    "        self.towers = tf.Variable(towersInit(shape=(nTasks, expertDim, hiddenDim), dtype=tf.float32), name=\"towers\")\n",
    "        # towers out\n",
    "        towersOut = tf.initializers.truncated_normal(mean=0.0, stddev=1.0)\n",
    "        self.outs = tf.Variable(towersOut(shape=(nTasks, hiddenDim, 1), dtype=tf.float32), name=\"outs\")\n",
    "        # target loss weights, (1, nTasks)\n",
    "        self.tasksWeights = tf.constant([[1.0, 1.0]])\n",
    "        assert self.tasksWeights.shape[1] == nTasks\n",
    "\n",
    "    def __call__(self, input, labels=None):\n",
    "        \"\"\"\n",
    "            @input: (batch, inputDim)\n",
    "            @labels: (batch, nTasks)\n",
    "        \"\"\"\n",
    "        input = tf.random.normal((bs, inputDim))\n",
    "        # (batch, 1, 1, inputDim), second dim is for expert broadcast, third dim is for matmul\n",
    "        input = tf.expand_dims(tf.expand_dims(input, axis=1), axis=1)\n",
    "\n",
    "        # (batch, 1, 1, inputDim) X (nExperts, inputDim, expertDim) -> (batch, nExperts, 1, expertDim) -> (batch, 1, nExperts, expertDim)\n",
    "        expertsOut = tf.transpose(tf.matmul(input, model.experts), [0, 2, 1, 3])\n",
    "\n",
    "        # (batch, 1, 1, inputDim) X (nTasks, inputDim, nExperts) -> (batch, nTasks, 1, nExperts)\n",
    "        # TODO: mask for seq padding\n",
    "        weights = tf.nn.softmax(tf.matmul(input, model.gates), 3)\n",
    "        # (batch, nTasks, 1, nExperts) X (batch, 1, nExperts, expertDim) -> (batch, nTasks, 1, expertDim)\n",
    "        towersIn = tf.matmul(weights, expertsOut)\n",
    "        # (batch, nTasks, 1, expertDim) X (nTasks, expertDim, hiddenDim) -> (batch, nTasks, 1, hiddenDim)\n",
    "        towersHidden = tf.nn.relu(tf.matmul(towersIn, model.towers))\n",
    "        # (batch, nTasks, 1, hiddenDim) X (nTasks, hiddenDim, 1) -> (batch, nTasks, 1, 1) -> (batch, nTasks)\n",
    "        outs = tf.squeeze(tf.matmul(towersHidden, model.outs), axis=[2, 3])\n",
    "\n",
    "        if labels is not None:\n",
    "            # train\n",
    "            # (batch, nTasks)\n",
    "            losses = tf.nn.sigmoid_cross_entropy_with_logits(labels, outs)\n",
    "            # loss fusion, (1, nTasks) X (batch, nTasks, 1) -> (batch, 1, 1) -> (batch, )\n",
    "            losses = tf.squeeze(tf.matmul(model.tasksWeights, tf.expand_dims(losses, axis=2)), axis=[1, 2])\n",
    "            losses = tf.reduce_mean(losses)\n",
    "            return losses\n",
    "        else:\n",
    "            # infer\n",
    "            return tf.nn.sigmoid(outs)\n",
    "\n",
    "bs = 4\n",
    "inputDim = 2\n",
    "expertDim = 2\n",
    "nExperts = 3\n",
    "nTasks = 2\n",
    "hiddenDim = 8\n",
    "\n",
    "model = MMOEDense(nTasks, nExperts, inputDim, expertDim, hiddenDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0289341, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def parseSample(sample):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "      'fea':tf.io.FixedLenFeature([], tf.string),\n",
    "      'marital' : tf.io.FixedLenFeature([], tf.int64),\n",
    "      'income': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    sample = tf.io.parse_single_example(sample, data)\n",
    "\n",
    "    fea = tf.io.parse_tensor(sample[\"fea\"], out_type=tf.float32)\n",
    "    marital = sample['marital']\n",
    "    income = sample['income']\n",
    "\n",
    "    return fea, marital, income\n",
    "\n",
    "train_batch_size = 4\n",
    "\n",
    "trainData = tf.data.TFRecordDataset(train_data_path).map(parseSample).batch(train_batch_size)\n",
    "\n",
    "for step, (fea, marital, income) in enumerate(trainData):\n",
    "    labels = tf.cast(tf.transpose(tf.stack([marital, income]), [1, 0]), tf.float32)\n",
    "    losses = model(fea, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "252189e587d1e2aeba4a06e91fa71896c7a7f6e22e918b9407c7cde4ef2d5985"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
